{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install wheels for Basemap\n",
    "- install Proj: https://proj.org/install.html#install\n",
    "- go to above link >> find Windows: click OSGeo4W >> download 64bit >> following above link's Window section to isntall PROJ\n",
    "- install basemap wheel and pyproj wheel from link: https://www.lfd.uci.edu/~gohlke/pythonlibs/\n",
    "- find: Basemap: a matplotlib toolkit for plotting 2D data on maps based on GEOS. \n",
    "- find: Pyproj: an interface to the PROJ library for cartographic transformations.\n",
    "- #### Important: pip install numpy --upgrade ###\n",
    "\n",
    "### Install wheels for geopandas \n",
    "Installing geopandas and its dependencies manually\n",
    "refer to: https://stackoverflow.com/questions/34427788/how-to-successfully-install-pyproj-and-geopandas\n",
    "\n",
    "Installing geopandas and its dependencies manually\n",
    "\n",
    "1. First and most important: do not try to directly pip install or conda install any of the dependencies – if you do, they will fail in some way later, often silently or obscurely, making troubleshooting difficult. If any are already installed, uninstall them now.\n",
    "\n",
    "2. Download the wheels for GDAL, Fiona, pyproj, rtree, and shapely from Gohlke. Make sure you choose the wheel files that match your architecture (64-bit) and Python version (2.7 or 3.5). If Gohlke mentions any prerequisites in his descriptions of those 5 packages, install the prerequisites now (there might be a C++ redistributable or something similar listed there)\n",
    "\n",
    "3. If OSGeo4W, GDAL, Fiona, pyproj, rtree, or shapely is already installed, uninstall it now. The GDAL wheel contains a complete GDAL installation – don’t use it alongside OSGeo4W or other distributions.\n",
    "\n",
    "4. Open a command prompt and change directories to the folder where you downloaded these 5 wheels.\n",
    "\n",
    "5. pip install the GDAL wheel file you downloaded. Your actual command will be something like: pip install\n",
    "GDAL-1.11.2-cp27-none-win_amd64.whl\n",
    "\n",
    "6. Add the new GDAL path to the windows PATH environment variable, something like C:\\Anaconda\\Lib\\site-packages\\osgeo\n",
    "pip install your Fiona wheel file, then your pyproj wheel file, then rtree, and then shapely.\n",
    "\n",
    "7. Now that GDAL and geopandas’s dependencies are all installed, you can just pip install geopandas from the command prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MilkRun Initial Routing Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\u279014\\\\Documents\\\\H_Drive\\\\7.AA Models\\\\12.Logistic_Optimization\\\\data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import general packages:\n",
    "from openpyxl import load_workbook\n",
    "import win32com.client\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Grouper\n",
    "from pandas import Timestamp\n",
    "import os\n",
    "import io\n",
    "import datetime as dt\n",
    "import time \n",
    "import feather\n",
    "import itertools\n",
    "from math import sqrt\n",
    "import csv\n",
    "import dask.dataframe as dd\n",
    "from datetime import datetime\n",
    "import timestring\n",
    "from IPython.core.display import display, HTML\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "# import modeling packages\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing, datasets\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "from scipy.spatial.distance import cdist,pdist\n",
    "from scipy import stats\n",
    "from scipy.sparse import *\n",
    "\n",
    "# import visualization packages:\n",
    "from matplotlib import pyplot as plt\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "import seaborn as sns\n",
    "# import ggplot\n",
    "%matplotlib inline\n",
    "\n",
    "# checking path and dir\n",
    "os.chdir('C:\\\\Users\\\\u279014\\\\Documents\\\\H_Drive\\\\7.AA Models\\\\12.Logistic_Optimization\\\\data')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_on_sphere_numpy(coordinate_df):\n",
    "    \"\"\"\n",
    "    Compute a distance matrix of the coordinates using a spherical metric.\n",
    "    :param coordinate_array: numpy.ndarray with shape (n,2); latitude is in 1st col, longitude in 2nd.\n",
    "    :returns distance_mat: numpy.ndarray with shape (n, n) containing distance in km between coords.\n",
    "    \"\"\"\n",
    "    # Radius of the earth in km (GRS 80-Ellipsoid)\n",
    "    EARTH_RADIUS = 6371.007176\n",
    "    km2mile_ratio = 0.62137\n",
    "\n",
    "    # Unpacking coordinates\n",
    "    latitudes = coordinate_df.loc[:,'latitude']\n",
    "    longitudes = coordinate_df.loc[:,'longitude']\n",
    "\n",
    "    # Convert latitude and longitude to spherical coordinates in radians.\n",
    "    degrees_to_radians = np.pi/180.0\n",
    "    phi_values = (90.0 - latitudes)*degrees_to_radians\n",
    "    theta_values = longitudes*degrees_to_radians\n",
    "\n",
    "    # Expand phi_values and theta_values into grids\n",
    "    theta_1, theta_2 = np.meshgrid(theta_values, theta_values)\n",
    "    theta_diff_mat = theta_1 - theta_2\n",
    "\n",
    "    phi_1, phi_2 = np.meshgrid(phi_values, phi_values)\n",
    "\n",
    "    # Compute spherical distance from spherical coordinates\n",
    "    angle = (np.sin(phi_1) * np.sin(phi_2) * np.cos(theta_diff_mat) + \n",
    "           np.cos(phi_1) * np.cos(phi_2))\n",
    "    arc = np.arccos(angle)\n",
    "\n",
    "    # Multiply by earth's radius to obtain distance in km\n",
    "    return np.nan_to_num(arc * EARTH_RADIUS * km2mile_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def riding_distance(riding_distance_matrix, geo):\n",
    "    \"\"\"\n",
    "    Compute a distance matrix of the coordinates using a spherical metric.\n",
    "    :param  \n",
    "        coordinate_df: numpy.ndarray with shape (n,n); riding_distance_matri: dataframe, col & index type: str \n",
    "        geo_zipcode: Data.Series, element type: str\n",
    "    :returns distance_mat: numpy.ndarray with shape (n, n) containing distance in km between coords.\n",
    "    \"\"\"\n",
    "    d_matrix = []\n",
    "    zipcodes = geo['zip_code'].apply(lambda x: str(x))\n",
    "    for i in zipcodes:\n",
    "        d_row = []\n",
    "        for j in zipcodes:\n",
    "            d_row.append(riding_distance_matrix.loc[i,j])\n",
    "        d_matrix.append(d_row)\n",
    "    return np.asarray(d_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_riding_distance_matrix(path,file):\n",
    "    riding_distance_matrix = pd.read_excel(os.path.join(path,file)).set_index('zipcode')\n",
    "    riding_distance_matrix.columns = riding_distance_matrix.columns.astype('str')\n",
    "    riding_distance_matrix.index = riding_distance_matrix.index.astype('str')\n",
    "    return riding_distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modeling Start >>>>>>\n",
    "## 1. Data_prep\n",
    "### 1.1 load saved feather supplier-cluster dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dictionary for osk_hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cass_zip_cluster = pd.read_csv('cass_zip_cluster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_copy = cass_zip_cluster.copy() # make a copy of original dataset\n",
    "cluster_copy = cluster_copy[cluster_copy.label != -1] # drop label(cluser) = -1, which do not belong to any group\n",
    "cluster_copy['shipping_date'] = '10-01-2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_copy['zip_code'] = cluster_copy.zip_code.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shipper_zip</th>\n",
       "      <th>unique_name</th>\n",
       "      <th>freq</th>\n",
       "      <th>ship_weight_freq_median</th>\n",
       "      <th>ship_weight_annum</th>\n",
       "      <th>shipment_count_annum</th>\n",
       "      <th>billed_amount_annum</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>state_abbreviation</th>\n",
       "      <th>label</th>\n",
       "      <th>shipping_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1752</td>\n",
       "      <td>aspensystem</td>\n",
       "      <td>monthly</td>\n",
       "      <td>261.0</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1194.81</td>\n",
       "      <td>1752</td>\n",
       "      <td>-71.54753</td>\n",
       "      <td>42.350909</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1887</td>\n",
       "      <td>staffordmfg</td>\n",
       "      <td>monthly</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.97</td>\n",
       "      <td>1887</td>\n",
       "      <td>-71.17031</td>\n",
       "      <td>42.558576</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1929</td>\n",
       "      <td>pendletonen</td>\n",
       "      <td>monthly</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>672.84</td>\n",
       "      <td>1929</td>\n",
       "      <td>-70.77925</td>\n",
       "      <td>42.631753</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1966</td>\n",
       "      <td>pendletonen</td>\n",
       "      <td>monthly</td>\n",
       "      <td>275.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.11</td>\n",
       "      <td>1966</td>\n",
       "      <td>-70.61727</td>\n",
       "      <td>42.659936</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2062</td>\n",
       "      <td>exidetechnologies</td>\n",
       "      <td>monthly</td>\n",
       "      <td>390.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>234.02</td>\n",
       "      <td>2062</td>\n",
       "      <td>-71.20166</td>\n",
       "      <td>42.185974</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shipper_zip        unique_name     freq  ship_weight_freq_median  \\\n",
       "0         1752        aspensystem  monthly                    261.0   \n",
       "1         1887        staffordmfg  monthly                    200.0   \n",
       "2         1929        pendletonen  monthly                    275.0   \n",
       "3         1966        pendletonen  monthly                    275.0   \n",
       "4         2062  exidetechnologies  monthly                    390.0   \n",
       "\n",
       "   ship_weight_annum  shipment_count_annum  billed_amount_annum zip_code  \\\n",
       "0             3392.0                   9.0              1194.81     1752   \n",
       "1              200.0                   1.0                86.97     1887   \n",
       "2             1715.0                   5.0               672.84     1929   \n",
       "3              275.0                   1.0               129.11     1966   \n",
       "4              780.0                   2.0               234.02     2062   \n",
       "\n",
       "   longitude   latitude state_abbreviation  label shipping_date  \n",
       "0  -71.54753  42.350909                 MA      0    10-01-2019  \n",
       "1  -71.17031  42.558576                 MA      0    10-01-2019  \n",
       "2  -70.77925  42.631753                 MA      0    10-01-2019  \n",
       "3  -70.61727  42.659936                 MA      0    10-01-2019  \n",
       "4  -71.20166  42.185974                 MA      0    10-01-2019  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_copy = cluster_copy[cluster_copy.ship_weight_freq_median < 45000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 choose supplier-cluster to run milkrun Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select top n supplier-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 2 # option for choosing supplier-cluster to run milkrun\n",
    "\n",
    "freq_selected = 'monthly'\n",
    "# label_no = Counter(cluster_copy.label).most_common()[rank-1][0]\n",
    "label_no = Counter(cluster_copy[cluster_copy.freq == freq_selected]['label']).most_common()[rank-1][0]\n",
    "cluster = cluster_copy[(cluster_copy.label == label_no) & (cluster_copy.freq == freq_selected)]\n",
    "\n",
    "# only append Greenville WH with sliced clusering\n",
    "\n",
    "greenville = pd.DataFrame([['54942', 'GREENVILLE_WH', 'weekly', 0, 0, 0, 0, '54942', -88.53557,44.293820, 'WI',999,'10-01-2019']], columns=cluster.columns)\n",
    "\n",
    "chanbersburg = pd.DataFrame([['17201', 'CHANBERSBURG_WH', 'weekly', 0, 0, 0, 0, '17201', -77.6614, 39.93112,'PA',999,'01-01-2019']], columns=cluster.columns)\n",
    "\n",
    "cass_zip_cluster_copy = greenville.append(cluster).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shipper_zip</th>\n",
       "      <th>unique_name</th>\n",
       "      <th>freq</th>\n",
       "      <th>ship_weight_freq_median</th>\n",
       "      <th>ship_weight_annum</th>\n",
       "      <th>shipment_count_annum</th>\n",
       "      <th>billed_amount_annum</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>state_abbreviation</th>\n",
       "      <th>label</th>\n",
       "      <th>shipping_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54942</td>\n",
       "      <td>GREENVILLE_WH</td>\n",
       "      <td>weekly</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54942</td>\n",
       "      <td>-88.535570</td>\n",
       "      <td>44.293820</td>\n",
       "      <td>WI</td>\n",
       "      <td>999</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1752</td>\n",
       "      <td>aspensystem</td>\n",
       "      <td>monthly</td>\n",
       "      <td>261.0</td>\n",
       "      <td>3392.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1194.81</td>\n",
       "      <td>1752</td>\n",
       "      <td>-71.547530</td>\n",
       "      <td>42.350909</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1887</td>\n",
       "      <td>staffordmfg</td>\n",
       "      <td>monthly</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.97</td>\n",
       "      <td>1887</td>\n",
       "      <td>-71.170310</td>\n",
       "      <td>42.558576</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1929</td>\n",
       "      <td>pendletonen</td>\n",
       "      <td>monthly</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>672.84</td>\n",
       "      <td>1929</td>\n",
       "      <td>-70.779250</td>\n",
       "      <td>42.631753</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1966</td>\n",
       "      <td>pendletonen</td>\n",
       "      <td>monthly</td>\n",
       "      <td>275.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129.11</td>\n",
       "      <td>1966</td>\n",
       "      <td>-70.617270</td>\n",
       "      <td>42.659936</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2062</td>\n",
       "      <td>exidetechnologies</td>\n",
       "      <td>monthly</td>\n",
       "      <td>390.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>234.02</td>\n",
       "      <td>2062</td>\n",
       "      <td>-71.201660</td>\n",
       "      <td>42.185974</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2135</td>\n",
       "      <td>millerberndsystems</td>\n",
       "      <td>monthly</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>572.97</td>\n",
       "      <td>2135</td>\n",
       "      <td>-71.153490</td>\n",
       "      <td>42.348418</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5201</td>\n",
       "      <td>jbmsherman</td>\n",
       "      <td>monthly</td>\n",
       "      <td>33258.0</td>\n",
       "      <td>312914.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34362.12</td>\n",
       "      <td>5201</td>\n",
       "      <td>-73.178730</td>\n",
       "      <td>42.882231</td>\n",
       "      <td>VT</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5301</td>\n",
       "      <td>milcut</td>\n",
       "      <td>monthly</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>492.74</td>\n",
       "      <td>5301</td>\n",
       "      <td>-72.623280</td>\n",
       "      <td>42.849957</td>\n",
       "      <td>VT</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6010</td>\n",
       "      <td>westfaliano</td>\n",
       "      <td>monthly</td>\n",
       "      <td>260.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2165.13</td>\n",
       "      <td>6010</td>\n",
       "      <td>-72.933650</td>\n",
       "      <td>41.682249</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6026</td>\n",
       "      <td>oshkoshcorp</td>\n",
       "      <td>monthly</td>\n",
       "      <td>349.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.18</td>\n",
       "      <td>6026</td>\n",
       "      <td>-72.727180</td>\n",
       "      <td>41.935501</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6824</td>\n",
       "      <td>rbcbearings</td>\n",
       "      <td>monthly</td>\n",
       "      <td>375.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.89</td>\n",
       "      <td>6824</td>\n",
       "      <td>-73.265744</td>\n",
       "      <td>41.163879</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11201</td>\n",
       "      <td>dresserargu</td>\n",
       "      <td>monthly</td>\n",
       "      <td>230.0</td>\n",
       "      <td>935.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>610.88</td>\n",
       "      <td>11201</td>\n",
       "      <td>-73.989070</td>\n",
       "      <td>40.695286</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11210</td>\n",
       "      <td>dresserargu</td>\n",
       "      <td>monthly</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>156.40</td>\n",
       "      <td>11210</td>\n",
       "      <td>-73.945520</td>\n",
       "      <td>40.627946</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11435</td>\n",
       "      <td>rosco</td>\n",
       "      <td>monthly</td>\n",
       "      <td>300.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>416.80</td>\n",
       "      <td>11435</td>\n",
       "      <td>-73.809860</td>\n",
       "      <td>40.700068</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11716</td>\n",
       "      <td>datadevice</td>\n",
       "      <td>monthly</td>\n",
       "      <td>520.0</td>\n",
       "      <td>8533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2061.76</td>\n",
       "      <td>11716</td>\n",
       "      <td>-73.113760</td>\n",
       "      <td>40.770042</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11743</td>\n",
       "      <td>telephonics</td>\n",
       "      <td>monthly</td>\n",
       "      <td>840.0</td>\n",
       "      <td>4028.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1411.60</td>\n",
       "      <td>11743</td>\n",
       "      <td>-73.411460</td>\n",
       "      <td>40.867498</td>\n",
       "      <td>NY</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17333</td>\n",
       "      <td>rhsheppardcompany</td>\n",
       "      <td>monthly</td>\n",
       "      <td>5272.0</td>\n",
       "      <td>5272.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1085.76</td>\n",
       "      <td>17333</td>\n",
       "      <td>-76.687826</td>\n",
       "      <td>39.972985</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18017</td>\n",
       "      <td>lehighvalleyplastics</td>\n",
       "      <td>monthly</td>\n",
       "      <td>352.0</td>\n",
       "      <td>4026.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1596.84</td>\n",
       "      <td>18017</td>\n",
       "      <td>-75.369260</td>\n",
       "      <td>40.645665</td>\n",
       "      <td>PA</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19702</td>\n",
       "      <td>exidetechnologies</td>\n",
       "      <td>monthly</td>\n",
       "      <td>289.0</td>\n",
       "      <td>3424.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2654.43</td>\n",
       "      <td>19702</td>\n",
       "      <td>-75.713860</td>\n",
       "      <td>39.626297</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>10-01-2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shipper_zip           unique_name     freq  ship_weight_freq_median  \\\n",
       "0        54942         GREENVILLE_WH   weekly                      0.0   \n",
       "1         1752           aspensystem  monthly                    261.0   \n",
       "2         1887           staffordmfg  monthly                    200.0   \n",
       "3         1929           pendletonen  monthly                    275.0   \n",
       "4         1966           pendletonen  monthly                    275.0   \n",
       "5         2062     exidetechnologies  monthly                    390.0   \n",
       "6         2135    millerberndsystems  monthly                   1410.0   \n",
       "7         5201            jbmsherman  monthly                  33258.0   \n",
       "8         5301                milcut  monthly                   7500.0   \n",
       "9         6010           westfaliano  monthly                    260.0   \n",
       "10        6026           oshkoshcorp  monthly                    349.0   \n",
       "11        6824           rbcbearings  monthly                    375.0   \n",
       "12       11201           dresserargu  monthly                    230.0   \n",
       "13       11210           dresserargu  monthly                    240.0   \n",
       "14       11435                 rosco  monthly                    300.0   \n",
       "15       11716            datadevice  monthly                    520.0   \n",
       "16       11743           telephonics  monthly                    840.0   \n",
       "17       17333     rhsheppardcompany  monthly                   5272.0   \n",
       "18       18017  lehighvalleyplastics  monthly                    352.0   \n",
       "19       19702     exidetechnologies  monthly                    289.0   \n",
       "\n",
       "    ship_weight_annum  shipment_count_annum  billed_amount_annum zip_code  \\\n",
       "0                 0.0                   0.0                 0.00    54942   \n",
       "1              3392.0                   9.0              1194.81     1752   \n",
       "2               200.0                   1.0                86.97     1887   \n",
       "3              1715.0                   5.0               672.84     1929   \n",
       "4               275.0                   1.0               129.11     1966   \n",
       "5               780.0                   2.0               234.02     2062   \n",
       "6              1410.0                   1.0               572.97     2135   \n",
       "7            312914.0                   9.0             34362.12     5201   \n",
       "8              7500.0                   1.0               492.74     5301   \n",
       "9              3270.0                   8.0              2165.13     6010   \n",
       "10              349.0                   1.0                96.18     6026   \n",
       "11              375.0                   1.0               115.89     6824   \n",
       "12              935.0                   4.0               610.88    11201   \n",
       "13              240.0                   1.0               156.40    11210   \n",
       "14              800.0                   3.0               416.80    11435   \n",
       "15             8533.0                   7.0              2061.76    11716   \n",
       "16             4028.0                   4.0              1411.60    11743   \n",
       "17             5272.0                   1.0              1085.76    17333   \n",
       "18             4026.0                   9.0              1596.84    18017   \n",
       "19             3424.0                   9.0              2654.43    19702   \n",
       "\n",
       "    longitude   latitude state_abbreviation  label shipping_date  \n",
       "0  -88.535570  44.293820                 WI    999    10-01-2019  \n",
       "1  -71.547530  42.350909                 MA      0    10-01-2019  \n",
       "2  -71.170310  42.558576                 MA      0    10-01-2019  \n",
       "3  -70.779250  42.631753                 MA      0    10-01-2019  \n",
       "4  -70.617270  42.659936                 MA      0    10-01-2019  \n",
       "5  -71.201660  42.185974                 MA      0    10-01-2019  \n",
       "6  -71.153490  42.348418                 MA      0    10-01-2019  \n",
       "7  -73.178730  42.882231                 VT      0    10-01-2019  \n",
       "8  -72.623280  42.849957                 VT      0    10-01-2019  \n",
       "9  -72.933650  41.682249                 CT      0    10-01-2019  \n",
       "10 -72.727180  41.935501                 CT      0    10-01-2019  \n",
       "11 -73.265744  41.163879                 CT      0    10-01-2019  \n",
       "12 -73.989070  40.695286                 NY      0    10-01-2019  \n",
       "13 -73.945520  40.627946                 NY      0    10-01-2019  \n",
       "14 -73.809860  40.700068                 NY      0    10-01-2019  \n",
       "15 -73.113760  40.770042                 NY      0    10-01-2019  \n",
       "16 -73.411460  40.867498                 NY      0    10-01-2019  \n",
       "17 -76.687826  39.972985                 PA      0    10-01-2019  \n",
       "18 -75.369260  40.645665                 PA      0    10-01-2019  \n",
       "19 -75.713860  39.626297                 DE      0    10-01-2019  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass_zip_cluster_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Samples Initialization with small selections: 100 locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\u279014\\Documents\\H_Drive\\7.AA Models\\12.Logistic_Optimization\\data'\n",
    "file = r'riding_distance_matrix.xlsx'\n",
    "riding_distance_matrix = load_riding_distance_matrix(path,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cass_zip_toy = cass_zip_cluster_copy[:100].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cass_zip_toy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1887'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1887'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d06d7698593f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistance_matrix_toy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mriding_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mriding_distance_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcass_zip_toy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-82695f93ca60>\u001b[0m in \u001b[0;36mriding_distance\u001b[1;34m(riding_distance_matrix, geo)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0md_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzipcodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0md_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mriding_distance_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0md_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1759\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1760\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1761\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1762\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1763\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1271\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1272\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1273\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1418\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m                 \u001b[1;31m# This is an elided recursive call to iloc/loc/etc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"not applicable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1766\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1767\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1769\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1962\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1964\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;31m# but will fail when the index is not present\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m             \u001b[1;31m# see GH5667\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3535\u001b[0m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3536\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3537\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3539\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '1887'"
     ]
    }
   ],
   "source": [
    "distance_matrix_toy = riding_distance(riding_distance_matrix, cass_zip_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distance_matrix_toy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ac5bdd3f0b5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistance_matrix_toy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'distance_matrix_toy' is not defined"
     ]
    }
   ],
   "source": [
    "distance_matrix_toy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U279014\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in arccos\n"
     ]
    }
   ],
   "source": [
    "distance_matrix_toy = distance_on_sphere_numpy(cass_zip_toy)\n",
    "df_distance_matrix = pd.DataFrame(distance_matrix_toy,index=cass_zip_toy.zip_code,columns=cass_zip_toy.zip_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_distance_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re_name column name as previously version\n",
    "replace_columns = ['shipper_zip', 'shipper_name', 'freq', 'ship_weight',\n",
    "       'ship_weight_annum', 'shipment_count_annum', 'billed_amount_annum',\n",
    "       'zip_code', 'longitude', 'latitude', 'state_abbreviation', 'label',\n",
    "       'shipping_date']\n",
    "\n",
    "cass_zip_toy.columns = replace_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\U279014\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in arccos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52596.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cass_zip_toy = cass_zip_toy.drop_duplicates(subset=['zip_code'])\n",
    "# unique_distance_matrix_toy = riding_distance(riding_distance_matrix, unique_cass_zip_toy)\n",
    "unique_distance_matrix_toy = distance_on_sphere_numpy(unique_cass_zip_toy)\n",
    "df_unique_distance_matrix = pd.DataFrame(unique_distance_matrix_toy,\n",
    "                                         index=unique_cass_zip_toy.zip_code,\n",
    "                                         columns=unique_cass_zip_toy.zip_code)\n",
    "\n",
    "ship_wight_list_toy = cass_zip_toy.ship_weight.tolist()\n",
    "sum(ship_wight_list_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model_Prep\n",
    "### I. Initilizing Opt-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_model(distance_matrix=0, \n",
    "                      ship_weight_list = 0, \n",
    "                      each_vehicle_capacity = 45000, \n",
    "                      num_vehicles = 30,\n",
    "                      nrLocations = 9):\n",
    "    \"\"\"Stores the data for the problem.\"\"\"\n",
    "    data = {}\n",
    "    data['distance_matrix']=distance_matrix\n",
    "    data['demands'] = ship_weight_list\n",
    "    data['vehicle_capacities'] = [each_vehicle_capacity]*num_vehicles\n",
    "    data['num_vehicles'] = num_vehicles\n",
    "    data['depot']=0\n",
    "    data['nrLocations'] = nrLocations\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Customized model output_NCv-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" optimize algorithm for accurate route \"\"\"\n",
    "def print_solution_3(data, manager, routing, assignment):\n",
    "    \"\"\"Prints assignment on console.\"\"\"\n",
    "    total_distance = 0\n",
    "    total_load = 0\n",
    "    \n",
    "    vehicle_routes = dict() # for list out the same truck pick zipcodes\n",
    "\n",
    "    for vehicle_id in range(data['num_vehicles']):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        plan_output = 'Route for vehicle {}:\\n'.format(vehicle_id)\n",
    "        plan_output_backward = 'Route for vehicle {}:\\n'.format(vehicle_id) # if backward is shorter path\n",
    "        route_distance = 0\n",
    "        route_load = 0\n",
    "        edge_distance = []\n",
    "        while not routing.IsEnd(index):\n",
    "            node_index = manager.IndexToNode(index)\n",
    "            route_load += data['demands'][node_index]\n",
    "            plan_output += ' {0} Load({1}) -> '.format(node_index, route_load)\n",
    "            plan_output_backward += ' {0} Load({1}) <- '.format(node_index, route_load) # if backward is shorter path\n",
    "            \n",
    "            previous_index = index            \n",
    "            index = assignment.Value(routing.NextVar(index))\n",
    "            \n",
    "            if vehicle_id in vehicle_routes:\n",
    "                vehicle_routes[vehicle_id].append(node_index)   # adding zipcodes to same truck\n",
    "            else:\n",
    "                vehicle_routes[vehicle_id] = [node_index]\n",
    "            \n",
    "            route_distance += routing.GetArcCostForVehicle(previous_index, index, vehicle_id)\n",
    "            edge_distance.append(routing.GetArcCostForVehicle(previous_index, index, vehicle_id))\n",
    "        \n",
    "        # adding destination to entire route\n",
    "\n",
    "        \"\"\" this situation is Fudging Headacheeeeeeee\"\"\"\n",
    "        # distance from greenville to first supplier is larger than last supplier to greenville, \n",
    "        # truck starts from first supplier, remove first span of driving from VRP\n",
    "        if edge_distance[0] >= edge_distance[-1]:\n",
    "            vehicle_routes[vehicle_id].append(0)\n",
    "            vehicle_routes[vehicle_id].pop(0)\n",
    "            route_distance = route_distance - edge_distance[0]\n",
    "            plan_output += ' {0} Load({1})\\n'.format(manager.IndexToNode(index),route_load)\n",
    "            plan_output += 'Distance of the route: {} miles\\n'.format(route_distance)\n",
    "            plan_output += 'Load of the route: {}\\n'.format(route_load)\n",
    "            # print(plan_output)\n",
    "            print(plan_output.replace('0 Load(0) ->  ',''))\n",
    "            total_distance += route_distance\n",
    "            total_load += route_load\n",
    "        \n",
    "        # truck starts form last supplier,remove last span of driving from VRP\n",
    "        else:\n",
    "            route_distance = route_distance - edge_distance[-1]\n",
    "            vehicle_routes[vehicle_id] = vehicle_routes[vehicle_id][::-1]\n",
    "            plan_output_backward += ' {0} Load({1})\\n'.format(manager.IndexToNode(index),route_load)\n",
    "            plan_output_backward += 'Distance of the route: {} miles\\n'.format(route_distance)\n",
    "            plan_output_backward += 'Load of the route: {}\\n'.format(route_load)\n",
    "            print(plan_output_backward)\n",
    "            total_distance += route_distance\n",
    "            total_load += route_load\n",
    "    print('Total distance of all routes: {} miles'.format(total_distance))\n",
    "    print('Total load of all routes: {}'.format(total_load))\n",
    "    return vehicle_routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Running Opt_Medel: initialize truck_max_capacity & total truck_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_v = 30\n",
    "num_stops = 7\n",
    "v_capacity = 45000\n",
    "n_route_location = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate data problem\n",
    "_data = create_data_model(distance_matrix=distance_matrix_toy,\n",
    "                         ship_weight_list=ship_wight_list_toy,\n",
    "                         each_vehicle_capacity=v_capacity,\n",
    "                         num_vehicles=num_v,\n",
    "                        nrLocations=n_route_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create routing index manager\n",
    "manager = pywrapcp.RoutingIndexManager(len(_data['distance_matrix']),_data['num_vehicles'],_data['depot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Routing Model\n",
    "routing = pywrapcp.RoutingModel(manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register transit callback\n",
    "def distance_callback(from_index, to_index):\n",
    "    from_node = manager.IndexToNode(from_index)\n",
    "    to_node = manager.IndexToNode(to_index)\n",
    "    return _data['distance_matrix'][from_node][to_node]\n",
    "\n",
    "transit_callback_index = routing.RegisterTransitCallback(distance_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cost of each arch\n",
    "routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension_name = 'Distance'\n",
    "# routing.AddDimension(transit_callback_index,\n",
    "#         0,  # no slack\n",
    "#         int(np.sum(data['distance_matrix'])),  # vehicle maximum travel distance\n",
    "#         True,  # start cumul to zero\n",
    "#         dimension_name)\n",
    "# distance_dimension = routing.GetDimensionOrDie(dimension_name)\n",
    "# distance_dimension.SetGlobalSpanCostCoefficient(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <<< try adding dimention for stops limitation >>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add count_stops constraint\n",
    "count_stop_callback = routing.RegisterUnaryTransitCallback(lambda index: 1)\n",
    "dimension_name = 'Counter'\n",
    "routing.AddDimension(count_stop_callback,\n",
    "                     0,\n",
    "                     v_capacity,\n",
    "                     True,\n",
    "                     'Counter'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_dimension = routing.GetDimensionOrDie(dimension_name)\n",
    "\n",
    "# add sovler to count stop numbers  \n",
    "for vehicle_id in range(num_v):\n",
    "    index = routing.End(vehicle_id)\n",
    "    solver = routing.solver()\n",
    "    solver.Add(counter_dimension.CumulVar(index) <= num_stops)\n",
    "\n",
    "#    solver.Add(counter_dimension.CumulVar(index).SetRange(3, 7)) \n",
    "#    Above >> [unsuccessful] set a range of stops  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Capacity constraint\n",
    "def demand_callback(from_index):\n",
    "    from_code = manager.IndexToNode(from_index)\n",
    "    return _data['demands'][from_code]\n",
    "\n",
    "demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)\n",
    "\n",
    "routing.AddDimensionWithVehicleCapacity(demand_callback_index,\n",
    "        0,  # null capacity slack\n",
    "        _data['vehicle_capacities'],  # vehicle maximum capacities\n",
    "        True,  # start cumul to zero\n",
    "        'Capacity')\n",
    "\n",
    "# Adding penalty for loading weight exceeds truck capacity\n",
    "penalty = 1000\n",
    "for node in range(1, len(_data['distance_matrix'])):\n",
    "    routing.AddDisjunction([manager.NodeToIndex(node)], penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting first solution heuristic.\n",
    "search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "search_parameters.first_solution_strategy = (routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the problem.\n",
    "assignment = routing.SolveWithParameters(search_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if assignment:\n",
    "    route_dictionary = print_solution_3(_data,manager,routing,assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Result Visualization to PowerBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def route_schedule(route_dictionary):\n",
    "    \"\"\" generat truck:pick_node map in dataFrame \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for k in route_dictionary.keys():\n",
    "        if len(route_dictionary[k]) == 1: # this step eliminate dummy trucks like #0,#1 trucks doing nothing\n",
    "            continue\n",
    "        for v in route_dictionary[k]:\n",
    "            df = df.append(pd.DataFrame({'truck_number':[k],'pick_node':[v]}))\n",
    "    return df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_schedule = route_schedule(route_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def route_schedule(route_dictionary):\n",
    "    \"\"\" generat truck:pick_node map in dataFrame \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for k in route_dictionary.keys():\n",
    "        if len(route_dictionary[k]) == 1: # this step eliminate dummy trucks like #0,#1 trucks doing nothing\n",
    "            continue\n",
    "        for v in route_dictionary[k]:\n",
    "            df = pd.concat([df, pd.DataFrame({'truck_number':[k],'pick_node':[v]})])\n",
    "    return df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_schedule = route_schedule(route_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "route_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: input of Graph must be unique distance matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_index(df,x):\n",
    "    '''\n",
    "    param:\n",
    "        df: distance matrix with UNIQUE index & columns\n",
    "        x: truck location source and truck location next-stop \n",
    "    return:\n",
    "        DataFrame: distance matrix\n",
    "    '''\n",
    "    try:\n",
    "        return df.loc[x[0],x[1]]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cass_zip_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "route_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "route_in_weight = route_schedule.merge(cass_zip_toy,left_on='pick_node',right_index=True,how='left')\n",
    "route_in_weight['next_zip_code'] = route_in_weight.groupby(['truck_number'])['zip_code'].shift(-1)\n",
    "route_in_weight['next_shipper_name'] = route_in_weight.groupby(['truck_number'])['shipper_name'].shift(-1)\n",
    "\n",
    "route_in_weight['milk_run_distance'] = route_in_weight[['zip_code','next_zip_code']].apply(lambda x: round(distance_index(df_unique_distance_matrix,x)),axis=1)\n",
    "route_in_weight['stop_number'] = route_in_weight.groupby('truck_number').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "route_in_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete later .... only for test purpose\n",
    "route_in_weight.to_csv(r'C:\\Users\\u279014\\Documents\\H_Drive\\7.AA Models\\12.Logistic_Optimization\\data\\route_test.csv',index=True,index_label='time_sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_in_weight.to_csv(r'C:\\Users\\u279014\\Documents\\H_Drive\\7.AA Models\\12.Logistic_Optimization\\data\\route_in_weight.csv',index=True,index_label='time_sequence')\n",
    "# route_in_weight.to_csv(r'S:\\CORP-Share\\DEPT\\IT\\DT-AA\\FY20\\GPSC\\UseCases\\8. Logistics Route Optimization\\route_in_weight.csv',index=True,index_label='time_sequence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Analytical Result: Miles & Cost Saving Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# distance matrix\n",
    "df_unique_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# routing work-order\n",
    "route_in_weight[['truck_number','shipper_name','zip_code','milk_run_distance','next_shipper_name','next_zip_code','ship_weight','miles']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_in_weight.shipper_state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tmc_miles = route_in_weight.miles.sum()\n",
    "total_milk_miles = route_in_weight.milk_run_distance.sum()\n",
    "miles_saving = (total_tmc_miles-total_milk_miles)\n",
    "print('-original_miles:{0} \\n-milkrun_miles:{1}\\n-miles reducton:{2}'.format(total_tmc_miles,total_milk_miles,miles_saving))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <<<<<<  Modeling Completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Impact >>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,file,sheet_name = None):\n",
    "    df = pd.read_excel(os.path.join(path,file),sheet_name=sheet_names)\n",
    "    df = pd.concat(df[frame] for frame in df.keys())\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.to_feather(os.path.join(path,'tmc_feather'))\n",
    "    return feather.read_dataframe(os.path.join(path,'tmc_feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\u279014\\Documents\\H_Drive\\7.AA Models\\12.Logistic_Optimization\\data'\n",
    "file = r'TMC_freight_rate.xlsx'\n",
    "sheet_names = ['Phase 1','Phase 2','Phase 3','Phase 4','Phase 5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(path=path,file=file,sheet_name=sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize dataframe colume names\n",
    "def col_name(df):\n",
    "    \"\"\"\n",
    "    this is to trim the data_frame column names to a unique format:\n",
    "    all case, replace space to underscore, remove parentheses\n",
    "    param df:\n",
    "        raw from share drive for\n",
    "    return:\n",
    "        polished data set with new column names\n",
    "    \"\"\"\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace('-','').str.replace(' ', '_').str.replace('(', '').\\\n",
    "                    str.replace(')', '').str.replace('\"','')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Slice tmc \"\"\"\n",
    "def clean_tmc(df, sink_state = 'WI', source_states = 'IL'):\n",
    "    \"\"\"\n",
    "    parameter: \n",
    "        df: original TMC dataset\n",
    "        sink_state: destination warehouse, only one locations allowed\n",
    "        source_states: shipping states, allowing multiple states as source state\n",
    "    return:\n",
    "        cleaned TMC including freight_cost from all states to sink_state\n",
    "    \"\"\"\n",
    "    # starndardize col name\n",
    "    df = col_name(df)\n",
    "    \n",
    "    # drop rows if all cols are nan\n",
    "    df.dropna(how='all',subset=['market_rate_over_quarter_decmar',\n",
    "       'market_rate_over_jan_2019mar_2020',\n",
    "       'market_rate_all_offers_jan_2019_mar_2020_no_fb',\n",
    "       'market_rate_all_offers_jan_2019_mar_2020_with_fb'],inplace=True)\n",
    "    \n",
    "    # generate freight_cost = market_rate_all_offers_jan_2019_mar_2020_no_fb or max of all\n",
    "    df['freight_cost'] = np.round(np.where(df.market_rate_all_offers_jan_2019_mar_2020_no_fb.isnull(),\n",
    "                               np.max(df,axis=1),\n",
    "                               df.market_rate_all_offers_jan_2019_mar_2020_no_fb),2)  \n",
    "    df['source_state'] = df.lane.apply(lambda x: x[:2]) # find source state short code\n",
    "    df['sink_state'] = df.lane.apply(lambda x: x[-2:]) # find sink state short code\n",
    "    \n",
    "    df = df[df.source_state.isin(source_states)] # slice only source state\n",
    "    df = df[df.sink_state.str.contains(sink_state)] # slice to include destination state only\n",
    "    df = df.groupby(['source_state','sink_state'])['freight_cost'].mean().reset_index() # average duplidate states to same destination, \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate cleaned TMC dataset\n",
    "source_states = cluster.shipper_state.unique()\n",
    "tmc = clean_tmc(df, sink_state='WI', source_states = source_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating full truck load cost\n",
    "route_in_weight['milk_run_cost'] = 0\n",
    "TL_cost = np.max(tmc.freight_cost)\n",
    "route_in_weight.loc[route_in_weight.groupby('truck_number').tail(1).index,'milk_run_cost'] = TL_cost\n",
    "route_in_weight.to_csv(r'C:\\Users\\u279014\\Documents\\H_Drive\\7.AA Models\\12.Logistic_Optimization\\data\\route_in_weight.csv',index=True,index_label='time_sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truck_used = len(route_in_weight.truck_number.unique())\n",
    "total_tmc_billed = route_in_weight.billed_amount.sum()\n",
    "total_milk_cost = round(np.max(tmc.freight_cost)*truck_used,2)\n",
    "# total_milk_cost = round(float(tmc.freight_cost)*truck_used,2)\n",
    "cost_saving = round((total_tmc_billed - total_milk_cost),2)\n",
    "print('-original_cost:{0} \\n-milkrun_cost:{1}\\n-cost reducton:{2}'.format(total_tmc_billed,total_milk_cost,cost_saving))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add potential Oshkosh Hubs to the route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clustering_main as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hub_dict(path, file, destination_list, route_in_weight, inbound_indicator='INBOUND'):\n",
    "    \"\"\"\n",
    "    param:\n",
    "        file: Cass FY19 Invoice Detail.csv\n",
    "        inbound_indicator: str\n",
    "        destination_list: list\n",
    "    return:\n",
    "        osk_hub_dict: dictionary, {supplier_name: [osk_warehouses...]\n",
    "    \"\"\"\n",
    "    _data = cm.ETL_data(path=path).col_name(file=file)\n",
    "    _data = _data[_data.inbound_outbound_indicator == inbound_indicator]\n",
    "    df_hub_dict = _data[_data.destination_city.isin(destination_list)][['shipper_name', 'shipper_city', 'shipper_state', 'shipper_zip', 'destination_city', 'destination_state', 'destination_zip']]\n",
    "    df_hub_dict = df_hub_dict.drop_duplicates(subset=['shipper_name', 'destination_city'])\n",
    "    df_hub_dict = df_hub_dict[df_hub_dict.shipper_name.isin(set(route_in_weight.shipper_name))]\n",
    "    df_hub_dict = df_hub_dict[df_hub_dict.shipper_zip.isin(set(route_in_weight.zip_code))]\n",
    "\n",
    "    hub_dict = defaultdict(set)\n",
    "    for sn, dc in zip(_data.shipper_name, _data.destination_city):\n",
    "        if dc in destination_list:\n",
    "            hub_dict[sn].add(dc)\n",
    "        else:\n",
    "            pass\n",
    "    return hub_dict, df_hub_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\u279014\\\\Documents\\\\H_Drive\\\\7.AA Models\\\\12.Logistic_Optimization\\\\data'\n",
    "file = 'Cass FY19 Invoice Detail.csv'\n",
    "destination_list = ['MILWAUKEE', 'OSHKOSH', 'GREENVILLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_dictionary, df_hub_dictionary = hub_dict(path=path, file=file, destination_list=destination_list, route_in_weight=route_in_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hub_dictionary.to_csv('hub_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "route_in_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hub_dictionary[df_hub_dictionary.shipper_name.isin(set(route_in_weight.shipper_name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
